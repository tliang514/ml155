{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "#import training data\n",
    "with open('training_data.txt','r') as train_f:\n",
    "    train_iter = csv.reader(train_f, delimiter='|')\n",
    "    trainlist = [i for i in train_iter]\n",
    "train_raw = np.asarray(trainlist)\n",
    "Label = train_raw[0,:]\n",
    "x_train = train_raw[1:,0:-1]\n",
    "y_train = train_raw[1:,-1]\n",
    "x_train = np.asarray(x_train, dtype='float64')\n",
    "y_train = np.asarray(y_train, dtype='int')\n",
    "\n",
    "#import testing data\n",
    "with open('testing_data.txt','r') as test_f:\n",
    "    test_iter = csv.reader(test_f, delimiter='|')\n",
    "    testlist = [i for i in test_iter]\n",
    "x_test = np.asarray(testlist[1:])\n",
    "x_test = np.asarray(x_test, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x_train = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test = preprocessing.normalize(x_test, norm='l2')\n",
    "x_train = preprocessing.scale(x_train)\n",
    "x_test = preprocessing.scale(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#feature selection: chi-square\\nfrom sklearn.feature_selection import chi2\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#feature selection: tfidf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(x_train)\n",
    "weight = transformer.idf_\n",
    "select = np.argsort(weight)[500:]\n",
    "x_train_select = x_train[:,select]\n",
    "y_train_select = y_train\n",
    "x_test_select = x_test[:,select]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split train and validation data\n",
    "#rowindex = [i for i in np.random.randint(0,x_train_select.shape[0], size=3000)]\n",
    "x_train_select_train = x_train_select[0:x_train_select.shape[0]/2,:]\n",
    "y_train_select_train = y_train_select[0:x_train_select.shape[0]/2]\n",
    "y_train_select_train[y_train_select_train==0] = -1\n",
    "x_train_select_valid = x_train_select[x_train_select.shape[0]/2:,:]\n",
    "y_train_select_valid = y_train_select[x_train_select.shape[0]/2:]\n",
    "y_train_select_valid[y_train_select_valid==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training SVM candidates...\n",
      "SVM Candidates training Done\n",
      "\n",
      "Start training Naive Bayes...\n",
      "Naive Bayes training Done\n",
      "\n",
      "Start training Decision Tree...\n",
      "Decision Tree training Down\n",
      "\n",
      "Start training SVM candidates with kernel poly...\n",
      "SVM Candidates training Done\n",
      "\n",
      "Start training RandomForest candidates...\n",
      "RandomForest candidates training Done\n",
      "\n",
      "Starting training KNN...\n",
      "KNN training Down\n",
      "\n",
      "Start training Logistic Regression\n",
      "\n",
      "Logistic Regression training Down\n",
      "\n",
      "Start Ensemble Selection...\n",
      "Ensemble Selection Done\n",
      "\n",
      "[139  75  85 ..., 155 155 127]\n",
      "0.566021867115\n",
      "[123 163 103 ..., 163 163  73]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "H = []    # store candidates\n",
    "\n",
    "#svm candidates\n",
    "print 'Start training SVM candidates...'\n",
    "from sklearn import svm\n",
    "c = [float(10**x) for x in range(-7, 4)]\n",
    "Gamma = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1., 2.]\n",
    "for i in range(len(c)):\n",
    "    for j in range(len(Gamma)):\n",
    "        clf = svm.SVC(C = c[i], gamma = Gamma[j], kernel='rbf')\n",
    "        clf.fit(x_train_select_train, y_train_select_train)\n",
    "        H.append(clf)\n",
    "print 'SVM Candidates training Done\\n'\n",
    "\n",
    "print 'Start training Naive Bayes...'\n",
    "#Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train_select_train, y_train_select_train)\n",
    "H.append(clf)\n",
    "\n",
    "#BernoulliNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(x_train_select_train, y_train_select_train)\n",
    "H.append(clf)\n",
    "\n",
    "#MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_select_train, y_train_select_train)\n",
    "H.append(clf)\n",
    "print 'Naive Bayes training Done\\n'\n",
    "\n",
    "print 'Start training Decision Tree...'\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Max_depth=[1, 2, 3, 4, 5, 7, 10, 20]\n",
    "N_estimators=[int(1.5**x) for x in range(1,15)]\n",
    "for i in range(len(Max_depth)):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=Max_depth[i])\n",
    "    for j in range(len(N_estimators)):\n",
    "        dlf = AdaBoostClassifier(base_estimator=clf, n_estimators=N_estimators[j])\n",
    "        dlf.fit(x_train_select_train, y_train_select_train)\n",
    "        H.append(dlf)\n",
    "print 'Decision Tree training Down\\n'\n",
    "\n",
    "\n",
    "print 'Start training SVM candidates with kernel poly...'\n",
    "Degree = [2, 3, 4, 5, 6]\n",
    "for i in range(len(c)):\n",
    "    for j in range(len(Degree)):\n",
    "        clf = svm.SVC(C = c[i], kernel='poly', degree=Degree[j])\n",
    "        clf.fit(x_train_select_train, y_train_select_train)\n",
    "        H.append(clf)\n",
    "print 'SVM Candidates training Done\\n'\n",
    "\n",
    "print 'Start training RandomForest candidates...'\n",
    "#RandomForest candidates\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "N_estimators = [100, 500, 1000]\n",
    "Max_depth = [i+1 for i in range(10)]\n",
    "Max_features = [int(1.5**x * np.sqrt(1000)) for x in range(-5,7)]\n",
    "for i in range(len(N_estimators)):\n",
    "    for j in range(len(Max_depth)):\n",
    "        for k in range(len(Max_features)):\n",
    "            clf = RandomForestClassifier(n_estimators=N_estimators[i], max_depth=Max_depth[j], max_features=Max_features[k])\n",
    "            clf.fit(x_train_select_train, y_train_select_train)\n",
    "            H.append(clf)\n",
    "print 'RandomForest candidates training Done\\n'\n",
    "\n",
    "print 'Starting training KNN...'\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "N_neighbors = [i+5 for i in range(10)]\n",
    "P = [1, 2]\n",
    "for i in range(len(N_neighbors)):\n",
    "    for j in range(len(P)):\n",
    "        clf = KNeighborsClassifier(n_neighbors=N_neighbors[i], p=P[j])\n",
    "        clf.fit(x_train_select_train, y_train_select_train)\n",
    "        H.append(clf)\n",
    "print 'KNN training Down\\n'\n",
    "\n",
    "print 'Start training Logistic Regression\\n'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Penalty = ['l1', 'l2']\n",
    "c = [float(10**x) for x in range(-7, 4)]\n",
    "for i in range(len(c)):\n",
    "    for j in range(len(Penalty)):\n",
    "        clf = LogisticRegression(penalty=Penalty[j], C=c[i])\n",
    "        clf.fit(x_train_select_train, y_train_select_train)\n",
    "        H.append(clf)\n",
    "print 'Logistic Regression training Down\\n'\n",
    "\n",
    "print 'Start Ensemble Selection...'\n",
    "result = H[0].predict(x_train_select_valid)\n",
    "score = sum(np.sign(result)==y_train_select_valid)*1.0/y_train_select_valid.shape[0]\n",
    "y_test = H[0].predict(x_test_select)\n",
    "model_number = 0\n",
    "for i in range(1, len(H)):\n",
    "    new = H[i].predict(x_train_select_valid)\n",
    "    y = np.sign(new + result)\n",
    "    if( (sum(y==y_train_select_valid)*1.0/y_train_select_valid.shape[0]) >= score ):\n",
    "        result = new + result\n",
    "        score = sum(y==y_train_select_valid)*1.0/y_train_select_valid.shape[0]\n",
    "        y_test = H[i].predict(x_test_select) + y_test\n",
    "        model_number += 1\n",
    "print 'Ensemble Selection Done\\n'\n",
    "\n",
    "\n",
    "\n",
    "print result\n",
    "print score\n",
    "print y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = np.sign(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test2 = np.zeros(x_test.shape[0])\n",
    "y_test2[y_test==1] = 1\n",
    "y_test2[y_test==0] = 1\n",
    "y_test2[y_test==-1] = 0\n",
    "y = np.zeros((x_test.shape[0],2))\n",
    "y[:,0] = [i+1 for i in range(x_test.shape[0])]\n",
    "y[:,1] = y_test2\n",
    "y = np.asarray(y, dtype='int')\n",
    "with open('solution.txt','w') as output:\n",
    "    a = csv.writer(output, delimiter=',')\n",
    "    a.writerows(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
